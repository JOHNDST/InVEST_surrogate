{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 20637,
     "status": "ok",
     "timestamp": 1731609142817,
     "user": {
      "displayName": "YUXIANG DONG",
      "userId": "14637966917688715638"
     },
     "user_tz": 300
    },
    "id": "1wLy0dqk-iO4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\INV\\lib\\site-packages\\natcap\\invest\\__init__.py:34: FutureWarning: \n",
      "        natcap.invest requires GDAL exceptions to be enabled. You must\n",
      "        call gdal.UseExceptions() to avoid unexpected behavior from\n",
      "        natcap.invest. A future version will enable exceptions on import.\n",
      "        gdal.UseExceptions() affects global state, so this may affect the\n",
      "        behavior of other packages.\n",
      "  warnings.warn(('''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "from shapely.geometry import box\n",
    "import natcap.invest.habitat_quality as habitat_quality\n",
    "import natcap.invest.urban_cooling_model as urban_cooling_model\n",
    "import natcap.invest.urban_nature_access as urban_nature_access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94FGutHO7V5g"
   },
   "source": [
    "# Run InVEST model \n",
    "- This code creates InVEST model inputs from processed pytorch files, run InVEST model for calculation outputs, then pack outputs for later deep learning training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"E:/Coding/CNN_InV_ReOrg/\")\n",
    "lulc = 'InVEST_Model/MainInputs/lulc.tif'\n",
    "work_dir_hq = 'InVEST_Model/HabitatQuality/WorkDir'\n",
    "threats_p = 'InVEST_Model/HabitatQuality/threat.csv'\n",
    "sensitivity_p = 'InVEST_Model/HabitatQuality/sensitivity.csv'\n",
    "work_dir_ucm = 'InVEST_Model/UrbanCooling/WorkDir'\n",
    "aoi = 'InVEST_Model/MainInputs/aoi.shp'\n",
    "et0 = 'InVEST_Model/MainInputs/et0.tif'\n",
    "pop = 'InVEST_Model/MainInputs/pop.tif'\n",
    "bio_csv = 'InVEST_Model/UrbanCooling/Biophysical_ucm_real.csv'\n",
    "work_dir_una = 'InVEST_Model/UrbanNatureAccess/WorkDir'\n",
    "attr_csv = \"InVEST_Model/UrbanNatureAccess/attr_unacsv.csv\"\n",
    "# This is the path of the pre-processed tensor files\n",
    "input_dir = 'Prosd'\n",
    "\n",
    "# This is the path of the temporary InVEST model inputs\n",
    "output_dir = \"InVEST_Model/MainInputs\"\n",
    "thrt_output_dir = \"InVEST_Model/HabitatQuality\"\n",
    "final_output_dir = \"Results_updt\"\n",
    "error_pop = \"Error_pop\"\n",
    "os.makedirs(error_pop, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1731609142818,
     "user": {
      "displayName": "YUXIANG DONG",
      "userId": "14637966917688715638"
     },
     "user_tz": 300
    },
    "id": "uK5lB4nT7n72"
   },
   "outputs": [],
   "source": [
    "def load_and_plot_pt_data(file_path):\n",
    "    \"\"\"\n",
    "    Load a .pt file, reshape the data to (3, 512, 512), and plot each channel in 3 subplots.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the .pt file.\n",
    "    \"\"\"\n",
    "    # Load the .pt file with weights_only=True for safety\n",
    "    data = torch.load(file_path, weights_only=True)\n",
    "\n",
    "    # Ensure the data has the expected shape\n",
    "    if data.shape != (3, 1, 512, 512):\n",
    "        raise ValueError(f\"Expected data shape (3, 1, 512, 512), but got {data.shape}\")\n",
    "\n",
    "    # Squeeze the second dimension to reshape the data to (3, 512, 512)\n",
    "    data = data.squeeze(1)  # Removes the dimension of size 1\n",
    "\n",
    "    # Plot each channel\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    for i in range(3):\n",
    "        axs[i].imshow(data[i].numpy(), cmap='viridis')\n",
    "        axs[i].set_title(f'Channel {i+1}')\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNKavDKL8063"
   },
   "source": [
    "## InVEST Input processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3473,
     "status": "ok",
     "timestamp": 1731609146288,
     "user": {
      "displayName": "YUXIANG DONG",
      "userId": "14637966917688715638"
     },
     "user_tz": 300
    },
    "id": "vyFfatjk9TsK"
   },
   "outputs": [],
   "source": [
    "# Load sample grids as a GeoDataFrame\n",
    "samples = gpd.read_file('Sample/Samplefishnets_32618.shp')\n",
    "\n",
    "def get_expanded_grid(cell, expand_size=1280):\n",
    "    # Find the center of the cell\n",
    "    minx, miny, maxx, maxy = cell.bounds\n",
    "    center_x = (minx + maxx) / 2\n",
    "    center_y = (miny + maxy) / 2\n",
    "\n",
    "    # Define the expanded box around the center\n",
    "    expanded_bounds = box(\n",
    "        center_x - expand_size,\n",
    "        center_y - expand_size,\n",
    "        center_x + expand_size,\n",
    "        center_y + expand_size\n",
    "    )\n",
    "\n",
    "    return expanded_bounds\n",
    "\n",
    "# This function is used to process the saved tensor data to GeoTIFF and shapefile format for InVEST inputs\n",
    "# Currently, it only supports the specified models: habitat_quality, urban_cooling_model, and urban_nature_access\n",
    "def process_samples(samples, torc, fid, output_dir, thrt_output_dir, expand_size=1280, threats=[(7, 10), (8, 11), (9, 12)], channel_names = ['lulc', 'et0', 'pop']):\n",
    "    \"\"\"\n",
    "    Load samples, match tensor by FID, expand bounds, and save as GeoTIFF and shapefile.\n",
    "\n",
    "    Parameters:\n",
    "    - samples: GeoDataFrame, loaded sample shapefile\n",
    "    - torc: torch.Tensor, indicating data to convert\n",
    "    - fid: int, feature ID to match in the sample shapefile\n",
    "    - output_dir: str, directory to save the output files\n",
    "    - thrt_output_dir: str, directory to save the threat output files\n",
    "    - expand_size: int, expansion size for the grid cell\n",
    "    - threats: list of int or tuple, threat values to extract from LULC. Tuple (7, 10) means lulc code 7 and 10 should be considered as one type of threat.\n",
    "               Threat output name needs to match the threat table. \n",
    "    - channel_names: list of str, names of the channels in the tensor data\n",
    "    Returns:\n",
    "    - None (saves GeoTIFF files and shapefile to the specified directory)\n",
    "    \"\"\"\n",
    "    # Filter the row in samples that matches the `FID`\n",
    "    sample_row = samples[samples['id'] == fid]\n",
    "\n",
    "    if len(sample_row) == 0:\n",
    "        raise ValueError(f\"No matching sample found for FID {fid}.\")\n",
    "\n",
    "    # Get the geometry and CRS\n",
    "    geometry = sample_row.geometry.values[0]\n",
    "    crs = samples.crs\n",
    "\n",
    "    # Expand the bounds\n",
    "    expanded_grid = get_expanded_grid(geometry, expand_size=expand_size)\n",
    "    minx, miny, maxx, maxy = expanded_grid.bounds\n",
    "\n",
    "    # Get the corresponding tensor data\n",
    "    tensor_data = torc.numpy()\n",
    "\n",
    "    # Check if tensor_data has 3 channels\n",
    "    if tensor_data.shape[0] != 3:\n",
    "        raise ValueError(\"Tensor data must have 3 channels.\")\n",
    "\n",
    "    # Define transform for the raster (GeoTIFF)\n",
    "    transform = from_bounds(minx, miny, maxx, maxy, tensor_data.shape[1], tensor_data.shape[2])\n",
    "\n",
    "    # Save each channel as a separate GeoTIFF\n",
    "\n",
    "    lulc_index = channel_names.index('lulc')\n",
    "    lulc_data = tensor_data[lulc_index]  # Extract lulc channel data\n",
    "    for i, channel_name in enumerate(channel_names):\n",
    "        output_path = f\"{output_dir}/{channel_name}.tif\"\n",
    "            # Check if the channel name is 'lulc'\n",
    "        if channel_name == 'lulc':\n",
    "            nodata_value = 255\n",
    "        else:\n",
    "            nodata_value = None  # No nodata for other channels\n",
    "\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=tensor_data.shape[1],\n",
    "            width=tensor_data.shape[2],\n",
    "            count=1,  # Single channel per file\n",
    "            dtype='int32',\n",
    "            crs=crs,\n",
    "            transform=transform,\n",
    "            nodata=nodata_value  # Set nodata value conditionally\n",
    "        ) as dst:\n",
    "            dst.write(tensor_data[i].astype(np.int32), 1)\n",
    "\n",
    "        # print(f\"Saved {output_path}\")\n",
    "\n",
    "    # Save the expanded grid as a shapefile\n",
    "    expanded_grid_gdf = gpd.GeoDataFrame({'id': [fid], 'geometry': [expanded_grid]}, crs=crs)\n",
    "    output_shapefile_path = f\"{output_dir}/aoi.shp\"\n",
    "    expanded_grid_gdf.to_file(output_shapefile_path)\n",
    "\n",
    "    # print(f\"Saved {output_shapefile_path}\")\n",
    "\n",
    "    # Handle threats if provided\n",
    "    lulc_meta = {\n",
    "        'driver': 'GTiff',\n",
    "        'height': lulc_data.shape[0],\n",
    "        'width': lulc_data.shape[1],\n",
    "        'count': 1,\n",
    "        'dtype': 'uint8',\n",
    "        'crs': crs,\n",
    "        'transform': transform,\n",
    "        'compress': 'lzw',\n",
    "    }\n",
    "    for threat in threats:\n",
    "        if isinstance(threat, int):\n",
    "            # Create binary mask for a single threat value\n",
    "            binary_mask = np.where(lulc_data == threat, 1, 0).astype(np.uint8)\n",
    "            out_filename = f\"threat_{threat}.tif\"\n",
    "        elif isinstance(threat, tuple):\n",
    "            # Create binary mask for multiple threat values\n",
    "            binary_mask = np.isin(lulc_data, threat).astype(np.uint8)\n",
    "            out_filename = f\"threat_{''.join(map(str, threat))}.tif\"\n",
    "        else:\n",
    "            raise ValueError(\"Threats must be a list of integers or tuples of integers.\")\n",
    "\n",
    "        # Write the binary mask to a new raster file\n",
    "        out_path = f\"{thrt_output_dir}/{out_filename}\"\n",
    "        with rasterio.open(out_path, 'w', **lulc_meta) as dst:\n",
    "            dst.write(binary_mask, 1)\n",
    "\n",
    "        # print(f\"Saved binary raster: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1731609147066,
     "user": {
      "displayName": "YUXIANG DONG",
      "userId": "14637966917688715638"
     },
     "user_tz": 300
    },
    "id": "jE1gSfblA8c9"
   },
   "outputs": [],
   "source": [
    "# Select one sample to test the function\n",
    "fid = 1008\n",
    "test = f\"Prosd/{fid}.pt\"\n",
    "torc = torch.load(test, weights_only=True).squeeze(1)\n",
    "output_dir = \"InVEST_Model/MainInputs\"\n",
    "thrt_output_dir = \"InVEST_Model/HabitatQuality\"\n",
    "process_samples(samples, torc, fid, output_dir, thrt_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1731609151701,
     "user": {
      "displayName": "YUXIANG DONG",
      "userId": "14637966917688715638"
     },
     "user_tz": 300
    },
    "id": "C6l3Hj2Go1e6"
   },
   "outputs": [],
   "source": [
    "# InVEST functions to run the models\n",
    "def hq(lulc, work_dir, threats_p, sensitivity_p):\n",
    "    '''\n",
    "    lulc: string, path to land use land cover raster\n",
    "    threats: list of ints, each int is a threat, this should contain transportation network\n",
    "    threat_dir: string, path to directory with threat rasters, including road networks\n",
    "    output_dir: string, path to output directory\n",
    "    file_prefix: string, prefix for output files\n",
    "    '''\n",
    "    suffix = 'test'\n",
    "    # run the habitat quality model\n",
    "    habitat_quality.execute({ 'lulc_cur_path': lulc,\n",
    "                 'threats_table_path': threats_p,\n",
    "                 'half_saturation_constant': 0.345,\n",
    "                 'results_suffix': suffix,\n",
    "                 'workspace_dir': work_dir,\n",
    "                 'sensitivity_table_path': sensitivity_p})\n",
    "    out_path = os.path.join(work_dir, f'quality_c_{suffix}.tif')\n",
    "    with rxr.open_rasterio(out_path) as hq:\n",
    "        hq_res = hq.copy()\n",
    "    return hq_res\n",
    "\n",
    "\n",
    "def ucm(lulc_path, work_dir_ucm, aoi_p, ref_eto_p, bio_p):\n",
    "    \"\"\"\n",
    "    Run the Urban Cooling Model from InVEST.\n",
    "\n",
    "    Parameters:\n",
    "    - lulc_path: str, path to the LULC raster input.\n",
    "    - work_dir: str, directory to save the model outputs.\n",
    "    Returns:\n",
    "    - float, mean value of the output map.\n",
    "    \"\"\"\n",
    "    suffix = 'test'\n",
    "    args = {\n",
    "        'workspace_dir': work_dir_ucm,\n",
    "        'results_suffix': suffix,\n",
    "        'lulc_raster_path': lulc_path,\n",
    "        't_ref': 22.6,\n",
    "        'ref_eto_raster_path': ref_eto_p,\n",
    "        'aoi_vector_path': aoi_p,\n",
    "        'biophysical_table_path': bio_p,\n",
    "        'green_area_cooling_distance': 450.0,\n",
    "        't_air_average_radius': 200.0,\n",
    "        'uhi_max': 2.06,\n",
    "        'do_energy_valuation': False,\n",
    "        'do_productivity_valuation': False,\n",
    "        'cc_method': 'factors',\n",
    "        'cc_weight_shade': 0.6,\n",
    "        'cc_weight_albedo': 0.2,\n",
    "        'cc_weight_eti': 0.2,\n",
    "    }\n",
    "\n",
    "    urban_cooling_model.execute(args)\n",
    "    # f\"{work_dir_ucm}/hm_{suffix}.tif\"\n",
    "    out_path = os.path.join(work_dir_ucm, f'hm_{suffix}.tif')\n",
    "    with rxr.open_rasterio(out_path) as ucm:\n",
    "        ucm_res = ucm.copy()\n",
    "    return ucm_res\n",
    "\n",
    "\n",
    "def una(lulc_path, work_dir_una, pop_p, aoi_p, attr_csv):\n",
    "    \"\"\"\n",
    "    Run the Urban Nature Access Model from InVEST.\n",
    "\n",
    "    Parameters:\n",
    "    - lulc_path: str, path to the LULC raster input.\n",
    "    - output_path: str, directory to save the model outputs.\n",
    "    - population_raster_path: str, path to the population raster input.\n",
    "    - admin_boundaries_vector_path: str, path to the administrative boundaries vector input.\n",
    "    - lulc_attribute_table: str, path to the LULC attribute table CSV.\n",
    "    Returns:\n",
    "    - float, mean value of the output map.\n",
    "    \"\"\"\n",
    "    suffix = 'test'\n",
    "    args = {\n",
    "        'workspace_dir': work_dir_una,\n",
    "        'results_suffix': suffix,\n",
    "        'lulc_raster_path': lulc_path,\n",
    "        'admin_boundaries_vector_path': aoi_p,\n",
    "        'lulc_attribute_table': attr_csv,\n",
    "        'population_raster_path': pop_p,\n",
    "        'urban_nature_demand': 45.0,  # Example value\n",
    "        'decay_function': 'dichotomy',\n",
    "        'search_radius_mode': 'radius per urban nature class',\n",
    "        'aggregate_by_pop_group': False,\n",
    "    }\n",
    "    urban_nature_access.execute(args)\n",
    "    out_path = f\"{work_dir_una}/output/urban_nature_balance_totalpop_{suffix}.tif\"\n",
    "    with rxr.open_rasterio(out_path) as una:\n",
    "        una_res = una.copy()\n",
    "\n",
    "    return una_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70573,
     "status": "ok",
     "timestamp": 1731609225763,
     "user": {
      "displayName": "YUXIANG DONG",
      "userId": "14637966917688715638"
     },
     "user_tz": 300
    },
    "id": "TGKEoeDKiRiD",
    "outputId": "920db529-8979-4d4a-822f-06585eb66600"
   },
   "outputs": [],
   "source": [
    "hq_test = hq(lulc, work_dir_hq, threats_p, sensitivity_p)\n",
    "ucm_test = ucm(lulc, work_dir_ucm, aoi, et0, bio_csv)\n",
    "una_test = una(lulc, work_dir_una, pop, aoi, attr_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62coo3GKxhO8"
   },
   "source": [
    "## Run InVEST models on clipped samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1731609239905,
     "user": {
      "displayName": "YUXIANG DONG",
      "userId": "14637966917688715638"
     },
     "user_tz": 300
    },
    "id": "T24HLBciit20"
   },
   "outputs": [],
   "source": [
    "# Collect all file names and create fid_list\n",
    "fid_list = []\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith('.pt'):\n",
    "        fid = int(file_name.split('.')[0])\n",
    "        fid_list.append(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0mQPScMxnmq"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93de1299c3f34b6383614f55942c6b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger('pygeoprocessing.geoprocessing').setLevel(logging.ERROR)\n",
    "\n",
    "os.makedirs(final_output_dir, exist_ok=True)\n",
    "\n",
    "for fid in tqdm(fid_list, desc=\"Processing files\"):\n",
    "    try:\n",
    "        # Load the file\n",
    "        test_path = f\"{input_dir}/{fid}.pt\"\n",
    "        torc = torch.load(test_path, weights_only=True).squeeze(1)\n",
    "        process_samples(samples, torc, fid, output_dir, thrt_output_dir)\n",
    "\n",
    "        # Run hq, ucm, and una functions\n",
    "        hq_test = hq(lulc, work_dir_hq, threats_p, sensitivity_p)\n",
    "        ucm_test = ucm(lulc, work_dir_ucm, aoi, et0, bio_csv)\n",
    "        una_test = una(lulc, work_dir_una, pop, aoi, attr_csv)\n",
    "\n",
    "        # Convert hq_test, ucm_test, and una_test into torch tensors\n",
    "        hq_tensor = torch.from_numpy(hq_test.values).float()\n",
    "        ucm_tensor = torch.from_numpy(ucm_test.values).float()\n",
    "        una_tensor = torch.from_numpy(una_test.values).float()\n",
    "\n",
    "        # Stack the tensors (3, 512, 512)\n",
    "        stacked_tensor = torch.stack([hq_tensor, ucm_tensor, una_tensor], dim=0)\n",
    "\n",
    "        # Save the stacked tensor as <fid>_res.pt in the output directory\n",
    "        final_output_path = f\"{final_output_dir}/{fid}_res.pt\"\n",
    "        torch.save(stacked_tensor, final_output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle the warning or exception and save the problematic file\n",
    "        error_path = f\"{error_pop}/{fid}_res_e.pt\"\n",
    "        torch.save({'fid': fid, 'error': str(e)}, error_path)\n",
    "        print(f\"Warning/Exception encountered for {fid}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO3bXD8wAW0Z/DEC5sGZbI8",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "INV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
